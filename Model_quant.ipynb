{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_quant.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O1BUPzzyEpd",
        "outputId": "c605b3d6-5cc1-4e0c-87bd-b5e05b3766cf"
      },
      "source": [
        "!pip install tensorflow_model_optimization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/8f/f6969dc64709c5c5e22cfd7057a83adbc927e6855a431b234168222cbf03/tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 12.7MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idHKJlbPvHRM"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import zipfile"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4zIpS9FyKpk"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dR5X3V5yKxz"
      },
      "source": [
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UydETggVyZRt",
        "outputId": "10b3d593-8501-4be2-c7e3-f954d9048a75"
      },
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF6fcksKyZWA"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eCIKk9NymV7"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX8m_4g-ymYj",
        "outputId": "abe1a875-f139-4810-e771-04d08550a754"
      },
      "source": [
        "model.fit(train_images,\n",
        "          train_labels,\n",
        "          epochs=5,\n",
        "          validation_split=0.1)\n",
        "\n",
        "_, baseline_model_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print('Baseline test accuracy: ', baseline_model_accuracy)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 20s 11ms/step - loss: 0.2856 - accuracy: 0.9225 - val_loss: 0.1054 - val_accuracy: 0.9733\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0966 - accuracy: 0.9729 - val_loss: 0.0744 - val_accuracy: 0.9812\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0717 - accuracy: 0.9791 - val_loss: 0.0629 - val_accuracy: 0.9845\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0601 - accuracy: 0.9824 - val_loss: 0.0655 - val_accuracy: 0.9835\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0525 - accuracy: 0.9840 - val_loss: 0.0595 - val_accuracy: 0.9840\n",
            "Baseline test accuracy:  0.982200026512146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWK11exSymeD",
        "outputId": "40e9035f-b90c-4182-9ec8-85961ed39449"
      },
      "source": [
        "keras_file = './baseline.h5'\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
        "print('Save baseline model to: ', keras_file)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save baseline model to:  ./baseline.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCPsbPjVzmze"
      },
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "validation_split = 0.1\n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvirAkuMznG5",
        "outputId": "e600269b-146b-4ecd-cb50-97613283aa2f"
      },
      "source": [
        "pruning_params = {\n",
        "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.5,\n",
        "                                                             final_sparsity=0.8,\n",
        "                                                             begin_step=0,\n",
        "                                                             end_step=end_step)\n",
        "}\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                          metrics=['accuracy'])\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2191: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_reshape  (None, 28, 28, 1)         1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d ( (None, 26, 26, 12)        230       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 2028)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 10)                40572     \n",
            "=================================================================\n",
            "Total params: 40,805\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 20,395\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0x2w-KNz1l8",
        "outputId": "1e240c1f-7771-4d7b-e15e-b5127086bf36"
      },
      "source": [
        "logdir = './logs'\n",
        "callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir, update_freq='epoch')\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_images, train_labels,\n",
        "                      batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                      callbacks=callbacks)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "422/422 [==============================] - 18s 38ms/step - loss: 0.0517 - accuracy: 0.9855 - val_loss: 0.0601 - val_accuracy: 0.9840\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 14s 33ms/step - loss: 0.0524 - accuracy: 0.9862 - val_loss: 0.0586 - val_accuracy: 0.9847\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 14s 33ms/step - loss: 0.0529 - accuracy: 0.9852 - val_loss: 0.0604 - val_accuracy: 0.9845\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 14s 34ms/step - loss: 0.0588 - accuracy: 0.9830 - val_loss: 0.0626 - val_accuracy: 0.9837\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 14s 33ms/step - loss: 0.0611 - accuracy: 0.9823 - val_loss: 0.0658 - val_accuracy: 0.9823\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 14s 32ms/step - loss: 0.0631 - accuracy: 0.9815 - val_loss: 0.0662 - val_accuracy: 0.9828\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 14s 32ms/step - loss: 0.0635 - accuracy: 0.9815 - val_loss: 0.0678 - val_accuracy: 0.9822\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 14s 33ms/step - loss: 0.0663 - accuracy: 0.9806 - val_loss: 0.0672 - val_accuracy: 0.9815\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 14s 34ms/step - loss: 0.0586 - accuracy: 0.9828 - val_loss: 0.0653 - val_accuracy: 0.9832\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 14s 32ms/step - loss: 0.0555 - accuracy: 0.9832 - val_loss: 0.0649 - val_accuracy: 0.9823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f192d617210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtp9MmxAz1uy",
        "outputId": "df2ba3cc-0b5e-46a6-e4cc-683d91d77e3d"
      },
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(test_images, test_labels, verbose=0)\n",
        "print('Baseline test accuracy: ', baseline_model_accuracy)\n",
        "print('Pruned test accuracy: ', model_for_pruning_accuracy)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline test accuracy:  0.982200026512146\n",
            "Pruned test accuracy:  0.9765999913215637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb1rhJZSz16C",
        "outputId": "0e35b45e-6dea-42e6-a70c-dfebced97ce7"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "pruned_keras_file = './baseline_pruned.h5'\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Save pruned keras model to: ', pruned_keras_file)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Save pruned keras model to:  ./baseline_pruned.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3cs0lj1z2JZ",
        "outputId": "cd7e9349-7bd0-4733-9ed7-859fefc48529"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "pruned_tflite_file = './baseline_pruned.tflite'\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "    f.write(pruned_tflite_model)\n",
        "\n",
        "print('save pruned TFLite model to: ', pruned_keras_file)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp2g3ii3oz/assets\n",
            "save pruned TFLite model to:  ./baseline_pruned.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHIGXDAs0uZy"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "    _, zipped_file = tempfile.mkstemp('.zip')\n",
        "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "        f.write(file)\n",
        "    return os.path.getsize(zipped_file)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9Y6fe2B0ukm",
        "outputId": "c7f748bd-448a-4fbd-b1da-d672941fa38b"
      },
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped baseline Keras model: 78195.00 bytes\n",
            "Size of gzipped pruned Keras model: 25938.00 bytes\n",
            "Size of gzipped pruned TFlite model: 25437.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp7k0Him0upi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792fd2cb-907e-4079-afa0-5e385b2780da"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "quantized_and_pruned_tflite_file = './baseline_pruned_quantized.tflite'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnqbn9zfd/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnqbn9zfd/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KYN2hnR0uxo"
      },
      "source": [
        "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
        "    f.write(quantized_and_pruned_tflite_model)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW78jRCz0uzr",
        "outputId": "704e69ec-4c3b-4262-b57e-531f54bf0974"
      },
      "source": [
        "print('Save quantized and pruned TFLite model to: ', quantized_and_pruned_tflite_file)\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save quantized and pruned TFLite model to:  ./baseline_pruned_quantized.tflite\n",
            "Size of gzipped baseline Keras model: 78195.00 bytes\n",
            "Size of gzipped pruned and quantized TFlite model: 8325.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma_qBw_O2ggn"
      },
      "source": [
        "def evaluate_model(interpreter):\n",
        "    input_index = interpreter.get_input_details()[0]['index']\n",
        "    output_index = interpreter.get_output_details()[0]['index']\n",
        "\n",
        "    # Run predictions on ever y image in the test dataset\n",
        "    prediction_digits = []\n",
        "    for i, test_image in enumerate(test_images):\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with the model's input data format\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "        # Run inference\n",
        "        interpreter.invoke()\n",
        "\n",
        "        # Post-processing: remove batch dimension and find the digit with highest probability\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib6qblKZ2gjg"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjEkWqEb2-OD"
      },
      "source": [
        "test_accuracy = evaluate_model(interpreter)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzff_r7s2-Xp",
        "outputId": "acbfb282-19af-4a07-e165-a13765e9d35c"
      },
      "source": [
        "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
        "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruned and quantized TFLite test_accuracy: 0.9766\n",
            "Pruned TF test accuracy: 0.9765999913215637\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}